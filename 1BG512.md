
# Population structure analysis
### Your task
Your overarching goal for these two afternoons is to gather information about your given populations so that you can answer the following questions about the Central African Rainforest Hunter-gatherers:

	1	Which of the RHGs are the least admixed?
	2	Are the RHGs more related to the Khoisan peoples than to the neighbouring Bantu-speakers?
	3	One of the RHGs populations stands out from the others. Why do think that is?

You will answer these questions with the support of the analyses that you produce.
You should write a short scientific report with references to the software used, what version you were running and what options you used to produce the results. It should be no more than two A4 pages of text (size ~12). Figures and tables not included.  

Your data comes from the following publications, it might be helpful to take a quick look at them if you want to know where the different populations were sampled.

Bulk of your data - [African Genome Variation project](https://www.nature.com/articles/nature13997)

Khoisan - [Schlebusch et al. 2012](https://science.sciencemag.org/content/338/6105/374.long)

You have also a set of Rainforest Hunter-Gathere genomes in the datset called `RHGs`. The RHGs are what's often reffered to as Pygmies in a derogatory fashion [https://en.wikipedia.org/wiki/Pygmy_peoples](https://en.wikipedia.org/wiki/Pygmy_peoples)

## Getting started

Before we start, here are some basic Unix/Linux commands if you are not used to working in a Unix-style terminal:
### Moving about:

```
    cd – change directory
    pwd – display the name of your current directory
    ls – list names of files in a directory
```
### File/Directory manipulations:

```
    cp – copy a file
    mv – move or rename files or directories
    mkdir – make a directory
    rm – remove files or directories
    rmdir – remove a directory
```
Display file content:

```
	cat - concatenate file contents to the screen or to a file
	less - open file for viewing (q to quit)
	nano - basic file editor
	vim - advanced file editor (:q to quit)
```	

## PART 1 Filtering and merging population genomic data using PLINK  	    

FYI: Link to PLINK site:[https://www.cog-genomics.org/plink2](https://www.cog-genomics.org/plink2)

PLINK is a software for fast and efficient filtering, merging, editing of large SNP datasets, and exports to different outputs directly usable in other programs. Stores huge datasets in compact binary format from which it reads in data very quickly.
 

#### Running the program
The software is already pre-installed on Rackham, you just have to load it. While on Rackham type:

```
module load bioinfo-tools 
module load plink/1.90b4.9 

```

Try it:

```
plink
```

#### Basic command structure: 
``` 
plink --filetypeflag filename --commandflag commandspecification --outputfilecommand --out outputfilename
```
For example to do filtering of missing markers at 10% frequency cutoff (reading-in a bed format file called file1, doing the filtering, writing to a ped format file called file2):

```
plink --bfile file1 --geno 0.1 --recode --out file2
```

#### Input formats:
File format summary:
ped format: usual format (.ped and .fam)
.ped contain marker and genotype info and .fam files contain sample info
bed format: binary/compact ped format (.fam .bim and .bed)
(.fam - sample info  .bim - marker info  and .bed - genotype info in binary format
tped format: transposed ped format (.tfam and .tped files)
tfam sample info, .tped marker and genotype info in transposed format
lgen format: long format (see manual, not used that often)



Setup
Navigate to the directory you want to work in.

```
cd path (change directory)
mkdir directory_name (create new directory)
```


```
cd /proj/uppmax2022-2-4/private/PCA_LAB #Uppmax project for this course
mkdir YOURNAME
```

Then move into your new directory:

```
cd YOURNAME
```

## Exercise 1 - Getting exercise datasets. Reading in bed file and converting to other formats 


#### The course meterial can be found at the following path:

```
/proj/uppmax2022-2-4/private/PCA_LAB
```

Make a soft link of the contents of the DATA folder to your own working directory. A soft link u unix systems is a pointer to a file, so you can "have" a files in several different directories without it taking up more space than just one copy.
This is done using the ln -s command, assuming that you are standing in your own working directory:

```
ln -s  ../DATA/Khoisans* .
ln -s  ../DATA/AGVP* .
ln -s  ../DATA/RHGs* .
```

These files contain SNPs from the three sources listed above. 
Look at the `.bim` (markers) and `.fam` (sample info) files by typing:

```
less AGVP.bim
``` 
press Q to quit `less`

do the same for the `.fam` file

```
less AGVP.fam 
```

Do the same thing for the two other datasets as well, `Khoisans` & `RHGs`.
If you paid attnetion you might have spotted that the different bim files use different naming schemes, this is going to cause issues down the line. PLINK will think that two SNPs with the same position and different names are two different SNPs and complain. 

We need to give the SNPs uniform names so that the different datasets work together.
In the SCRIPTS folder the is a python script that does this, it will give each SNP a new name based on the position of the SNP.
You need to give it the path to your `.bim` files, one at a time.


```
../SCRIPTS/rename_SNP.py Khoisans.bim
```

This will create a copy of the bim file which you will have to rename to take the place of the original file, use the move command `mv`: 

```
mv Khoisans.bim_pos_names Khoisans.bim
```
Repeat for the other two datasets. 


As mentioned before the `.bim` file store the variant markers present in the data and `.fam` lists the samples. (you can try to look at the .bed as well, but this file is in binary format and cannot be visualized as text, if you want to see the specific genotype info you must export the bed format to a ped format)



Read in a  bed file dataset and convert to ped format by typing/pasting in:

```
plink --bfile Khoisans --recode --out Khoisans_ped 
```

#### Look at the info that plink prints to the screen. How many SNPs are there in the data? How many individuals? 

#### Look at first few lines of the newly generated .map (sample info) and .ped (marker and genotype info) files using the more command as demonstrated above

Read in bed/ped file and convert to tped

```
plink --bfile Khoisans --recode transpose --out Khoisans_tped 
plink --file Khoisans_ped --recode transpose --out Khoisans_tped 
```

Do  you see the difference in the two commands above for reading from a bed (--bfile) and reading from a ped (--file) file. Which one take longer to read-in?

Look at first few lines of the  `.tfam` and `.tped` files by using the `less` command

#### Can you see what symbol is used to encode missing data?

Note - try to always work with bed files, they are much smaller and takes less time to read in. 
See this for yourself by inspecting the difference in file sizes:

```
ls -lh * 
```

Plink can convert to other file formats as well, you can have a look in the manual for the different types of conversions.

## Exercise 2 - Data filtering. Missingness, HWE and MAF
Now we will start to clean our data before further analysis.
In the interest of time we will only be working with the Khoisan dataset in the section, if there is time though go through and do Optional 1 in which we will work through all datasets and merge them into one. 

Start by looking at the missingness information for each individual and SNP by typing:

```
plink  --bfile Khoisans --missing --out test1miss
```

Look at the two generated files by using the `less` command (q to quit)

```
less test1miss.imiss
less test1miss.lmiss
```

The `.imiss` contains the individual missingness and the `.lmiss` the marker missingness.
Do you understand the columns of the files? The last three columns are the number of missing, the total and the fraction of missing markers and individuals for the two files respectively

We will start our filtering process with filtering for missing data
First we filter for marker missingness, we have 10000’s of markers but only 69 individuals for the Khoisan, so we want to try to save filtering out unnecessary individuals

Paste in the command below to filter out markers with more than 10% missing data

```
plink --bfile Khoisans --geno 0.1 --make-bed --out Khoisans_geno_0.1 
```

Look at the screen output, how many SNPs were excluded?

Now we will filter for individual missingness.
Paste in the command below to filter out ind

```
plink --bfile Khoisans_geno_0.1 --mind 0.15 --make-bed --out Khoisans_geno_0.1_mind_0.15 
```

Look at the screen output, how many individuals were excluded?

To filter for minimum allele frequency is not always optimal, especially if you are going to merge your data with other datasets in which the alleles might be present. So normaly you would do it only after merging.
But we will apply a MAF filter in this case

Filter data for a minimum allele frequency of 1% by pasting in:

```
plink --bfile Khoisans_geno_0.1_mind_0.15 --maf 0.01 --make-bed --out Khoisans_geno_0.1_mind_0.15_maf_0.01 
```

How many SNPs are left?

Now we will filter for SNPs out of Hardy-Weinberg equilibrium. Most likely, SNPs out of HWE usually indicates problems with the genotyping. However, to avoid filtering out SNPs that are selected for/against in certain groups (especially when working with case/control data) filtering HWE per group is recommended. After, only exclude the common SNPs that falls out of the HWE in the different groups.

For reasons of time we will now just filter the entire dataset for SNPs that aren’t in HWE with a significance value of 0.001

```
plink --bfile Khoisans_geno_0.1_mind_0.15_maf_0.01 --hwe 0.001 --make-bed --out Khoisans_geno_0.1_mind_0.15_maf_0.01_hwe_0.001
```

Look at the screen. How many SNPs were excluded?

If you only what to look at the HWE stats you can do as follows. By doing this command you can also obtain the observed and expected heterozygosities. 

```
plink --bfile Khoisans_geno_0.1_mind_0.15_maf_0.01_hwe_0.001 --hardy --out hardy
```

Look at file hardy.hwe, see if you understand the output?

There are additional filtering steps that that you can go further. PLINK site on the side lists all the cool commands that you can use to treat your data. Usually we also filter for related individuals and do a sex-check on the X-chromosome to check for sample mix-ups. 

You normally also want to merge your dataset with already published ones or with some other data that you have access and you are interested to combine. If you have extra time we recommend you to do the exercise *OPTIONAL 1*. However, if you don’t, please just read through so you can have a grasp about how and why you do those steps.


=============================================================================

## Data Merging and strand flipping.

The next step would be to start merging your data to comparative datasets. Due to time constraints we are now skipping this step and continuing to Part 2. You can however, work through this exercise optionally.
Usually when you merge your data with another dataset there are strand issues. The SNPs in the other dataset might be typed on the reverse DNA strand and yours on the forward, or vice versa. Therefore you need to flip the strand to the other orientation for all the SNPs where there is a strand mismatch. One should not flip C/G and A/T SNPs because one cannot distinguish reverse and forward orientation (i.e. C/G becomes G/C unlike other SNPs i.e. G/T which become C/A). Therefore before merging and flipping all A/T and C/G SNPs must be excluded. However this can be a problem since some of your SNPs in your dataset may be monomorphic, when you dont apply the MAF filter. I.E in the bim file they will appear as C 0 (with 0 meaning missing). So you dont know what kind of SNP it is, it can be C G or C T for instance, if it is C G it needs to be filtered out but not if it is C T.

Therefore, before merging our data to other datasets it is important to first merge your data with a fake / reference_individual, that you prepare, which is heterozygous at every SNP position. This “fake” reference individual you can easily prepare from the SNP info file you get from the genotyping company or your own genomics processing software (such as Genome Studio from Illumina). You can also prepare it from data downloaded for each SNP from a web-database such as dbSNP. 

Have you noticed that PLINK sometimes generates a .nof file and in the log file output the following is mentioned
902 SNPs with no founder genotypes observed
Warning, MAF set to 0 for these SNPs (see --nonfounders)
This is the monomorphic SNPs in you data.

So our first step will be merging with our other datasets.


Make a list of CG and AT SNPs in your data:

```
sed 's/\t/ /g' Khoisans_geno_0.1_mind_0.15_maf_0.01_hwe_0.001.bim | grep " C G" >ATCGlist
sed 's/\t/ /g' Khoisans_geno_0.1_mind_0.15_maf_0.01_hwe_0.001.bim | grep " G C" >>ATCGlist
sed 's/\t/ /g' Khoisans_geno_0.1_mind_0.15_maf_0.01_hwe_0.001.bim | grep " A T" >>ATCGlist
sed 's/\t/ /g' Khoisans_geno_0.1_mind_0.15_maf_0.01_hwe_0.001.bim | grep " T A" >>ATCGlist
```

Excude the CG and AT snps:

```
plink --bfile Khoisans_geno_0.1_mind_0.15_maf_0.01_hwe_0.001 --exclude ATCGlist --make-bed --out Khoisan_extracted
```


Extract your SNPs of interest from the AGVP (remember you filtered out a number of SNPs already)

```
plink --bfile AGVP --extract Khoisan_extracted.bim --make-bed --out AGVP_1
```



Merge Khoisan and AGVP 

```
plink --bfile AGVP_1 --bmerge Khoisan_extracted --make-bed --out Khoisan_AGVP
```

An error is generated because of the strand mismatches. The generated file `Khoisan_AGVP-merge.missnp`
contains the info on the SNPs where there are mismatches - flip the strand of these SNPs in your data.

```
plink --bfile AGVP_1 --flip Khoisan_AGVP-merge.missnp --make-bed --out  AGVP_2  
```

Try to merge again:

```
plink --bfile AGVP_2 --bmerge Khoisan_extracted --make-bed --out Khoisan_AGVP  
```

Now it works.
No .nof file is generated which means none of your SNPs are monomorphic anymore.

Now we need to merge in the RHGs data as well.

As before, first extract the SNPs we have in our data.

```
plink --bfile RHGs --extract Khoisan_AGVP.bim --make-bed --out RHGs_1
```

Now we will merge our data with the downloaded data

```
plink --bfile RHGs_1 --bmerge Khoisan_AGVP --make-bed --out Khoisan_AGVP_RHGs 
```

Another strand issue, flip the strands of the RHGs

```
plink --bfile RHGs_1 --flip Khoisan_AGVP_RHGs-merge.missnp --make-bed --out RHGs_2
```

Try to merge again:

```
plink --bfile RHGs_2 --bmerge Khoisan_AGVP --make-bed --out Khoisan_AGVP_RHGs
```

It works now. Look at your screen output. You will see that the new file only contains the ovelapping SNPs between the two datasets.

```
plink --bfile Khoisan_AGVP_RHGs  --geno 0.1 --make-bed --out Khoisan_AGVP_RHGs_geno_0.1
```

How many SNPs are left for your analyses?

Last thing to do is to extract your fake/Ref_ind from your data.

```
plink --bfile Khoisan_AGVP_RHGs_geno_0.1 --remove ../DATA/fake.fam --make-bed --out Merged_data
```

This is the final files for the next exercise. 

Now you have generated your input files for the next exercise which will deal with population structure analysis. You will look at the population structure of your unknown samples in comparison to the known reference populations from HapMap and HGDP.


=============================================================================

## Population structure inference with ADMIXTURE
Using ADMIXTURE/PONG and principal component analysis with EIGENSOFT 

In case you could not get the merging and flipping to work then, please copy these files into your folder, you might have to modify the command if you have a different folder structure than suggested in the lab:

```
cp ../DATA/Merged_data.bed .
cp ../DATA/Merged_data.bim .
cp ../DATA/Merged_data.fam .
```

Admixture is a similar tool to STRUCTURE but runs much quicker, especially on large datasets. STRUCTURE used to be the dominating tool in the field, but has now been surpassed by ADMIXTURE.
ADMIXTURE runs directly from .bed or .ped files and need no extra parameter file preparation. You do not specify burnin and repeats, ADMIXTURE exits when it converged on a solution (Delta < minimum value)

First load it from the module system:

```
module load ADMIXTURE/1.3.0
```


A basic ADMIXTURE run looks like this (don't run this):

```
admixture -s time  Merged_data.bed 2
```

This command execute the program with a seed set from system clock time, it gives the input file (remember the extension) and the K value at which to run ADMIXTURE (2 in the previous command).

For ADMIXTURE you also need to run many iterations at each K value, thus a compute cluster and some scripting is useful.

Save the code below to a script or run it straight as it is in the terminal to run Admixture for K = 2-10 with 10 iterations/repetitions at each K value:

```
for i in {2..10};
    do                                                                                      
    for j in {1..10};                                                                                      
        do
        admixture -s time  Merged_data.bed ${i} 
        mv  Merged_data.${i}.Q  Merged_data.${i}.Q.${j};
        mv  Merged_data.${i}.P  Merged_data.${i}.P.${j};
    done
done
```

Look for a while at the screen output.
You will see a short burin, followed by the repeats, and the run stop if delta goes below a minimum value. For K=2 this happens quickly, but the higher Ks take longer. It will take a while for each iteration, and we are doing 9 different Ks and repeating it 10 times each, this will tak around 24 h's to complete in this fashion.
Instead I have precalcuated this for you so *abort the analysis with ctrl - C* and copy the output from the DATA/ADMIXTURE_OUTPUT folder.

Look at the generated output files. What do they contain?

You can quickly look at your admixture output in R by opening R and pasting in the code below. It will plot the first three iterations for the first 6 Ks.

```
WD<-getwd()
setwd(WD)

k2_1 <- read.table("2.1/Merged_data.2.Q")
k2_2 <- read.table("2.2/Merged_data.2.Q")
k2_3 <- read.table("2.3/Merged_data.2.Q")
k3_1 <- read.table("3.1/Merged_data.3.Q")
k3_2 <- read.table("3.2/Merged_data.3.Q")
k3_3 <- read.table("3.3/Merged_data.3.Q")
k4_1 <- read.table("4.1/Merged_data.4.Q")
k4_2 <- read.table("4.2/Merged_data.4.Q")
k4_3 <- read.table("4.3/Merged_data.4.Q")
k5_1 <- read.table("5.1/Merged_data.5.Q")
k5_2 <- read.table("5.2/Merged_data.5.Q")
k5_3 <- read.table("5.3/Merged_data.5.Q")
k6_1 <- read.table("6.1/Merged_data.6.Q")
k6_2 <- read.table("6.2/Merged_data.6.Q")
k6_3 <- read.table("6.3/Merged_data.6.Q")

pdf (file ="Admixture_Plot1.pdf", width =25, height = 40, pointsize =10)
par(mfrow=c(15,1))
barplot(t(as.matrix(k2_1)), col=rainbow(2),border=NA)
barplot(t(as.matrix(k2_2)), col=rainbow(2),border=NA)
barplot(t(as.matrix(k2_3)), col=rainbow(2),border=NA)
barplot(t(as.matrix(k3_1)), col=rainbow(3),border=NA)
barplot(t(as.matrix(k3_2)), col=rainbow(3),border=NA)
barplot(t(as.matrix(k3_3)), col=rainbow(3),border=NA)
barplot(t(as.matrix(k4_1)), col=rainbow(4),border=NA)
barplot(t(as.matrix(k4_2)), col=rainbow(4),border=NA)
barplot(t(as.matrix(k4_3)), col=rainbow(4),border=NA)
barplot(t(as.matrix(k5_1)), col=rainbow(5),border=NA)
barplot(t(as.matrix(k5_2)), col=rainbow(5),border=NA)
barplot(t(as.matrix(k5_3)), col=rainbow(5),border=NA)
barplot(t(as.matrix(k6_1)), col=rainbow(6),border=NA)
barplot(t(as.matrix(k6_2)), col=rainbow(6),border=NA)
barplot(t(as.matrix(k6_3)), col=rainbow(6),border=NA)
dev.off()
q()
N

```

This creates the pdf `Admixture_Plot1.pdf`. The bar plots have the individual K cluster asignment for the 3 iterations at K=2-6. The order of individuals is in file “Merged_data.fam”. You can dowload it to look at it or use `evince` on Rackham.

## PONG 

The method above is a way to quickly check your data, but you have to look at each iteration separately. This makes it hard to get a good overview of the results. We instead combine the different iterations using a software called PONG. 

A typical PONG command looks like this:

```
pong -m your_filemap.txt -i your_ind2pop.txt -n your_pop_order.txt -g
```

To be able to run PONG we thus need to generate three different files.

The first being the filemap. This is the only input that is strictly required to run PONG. IT consists of three columns.
From the PONG manual: 

```
Column 1. The runID, a unique label for the Q matrix (e.g. the string “run5_K7”).

Column 2. The K value for the Q matrix. Each value of K between Kmin and Kmax must
be represented by at least one Q matrix in the filemap; if not, pong will abort.
Column 3. The path to the Q matrix, relative to the location of the filemap. 
```

In order to create what we need we can run the following loop:

```
for k in {2..10};
do
    for j in {1..10};
    do
    echo -e "k${k}_r${j}\t$k\t${k}.${j}/Merged_data.${k}.Q" >> Merged_data_filemap.txt
    done
done
```

The next file we need to create is the ind2pop file. It is just a list of which population each individual belongs to.
We have this information in the `.fam` file so we can just cut out the field we need:

```
cut -f 1 -d " " Merged_data.fam > Merged_data_ind2pop.txt
``` 


The poporder file is a key between what your populations are called and what "Proper" name you want to show up in your final plot. Lucky for us we already have reasonable names, but many other datasets have names like `YRI` & `CEU`. That can be a bit hard to understand if you are not used to those abreviations. 
This file also dictates the order of the populations in the plot, so if you want to move them around then change the order. 
*Note that the file needs to be tab delimited* 

```
Ethiopians
Baganda
Banyarwanda
Barundi
Kalenjin
Kikuyu
Igbo
GaAdangbe
Jola
Fula
Mandinka
Wolof
Sotho
Zulu
Baka
Bakoya
Bezan
Biaka
Mbuti
Juhoansi
Karretjie
Khomani
Khwe
Xun
```

So just copy this into a file called `Merged_data_poporder.txt`
I suggest that you use the built in text editor `nano`, it is quite "noob"-friendly.

```
nano
```

Note that the `^` caracter used to do commands in `nano` is `control`.

Now we have all the file we need. Time to run PONG.
PONG is available through the module system on Uppmax.
*(You also will need to have the bioinfo-tools module loaded)*

```
module load pong 
```

Since we are several people who are going to run PONG at the same time we need to use different port, otherwise we will collide with each other. The default port for PONG is 4000. Any other free port will work, like 4001, 2 etc. Make sure you are using a uniq port before proceeding 


```
pong -m Merged_data_filemap.txt -i Merged_data_ind2pop.txt -n Merged_data_poporder.txt -g --port YOUR_PORT_NUMBER_HERE
```

When PONG is done it will start hosting a webserver wich displays the results at port 4000 by default:  http://localhost:4000
To view files interactively you need to have a X11 connection. So when you connect to rackham do:


```
ssh -AY YOUR_USERNAME_HERE@rackham.uppmax.uu.se

```
 
**In a new tab ** (if you didn't put PONG in the background) type:

```
firefox http://localhost:YOUR_PORT_NUMBER_HERE
```


#### What do you see? What information does this give you about our populations?

Once you are finished with looking at the PONG output you can click and save some output to file and hen close program by hitting `ctrl - c` in the terminal tab running it. 



=============================================================================



## Principal component Analysis

The last population structure method we will look at is Principal Components Analysis. We will use PLINK for this as well. This is used with the `--pca` option followed by the number of components that you want, 10 should be plenty. 

```
plink --bfile Merged_data --pca 10
```


Eigenvectors are written to plink.eigenvec, and top eigenvalues are written to plink.eigenval

To work out the percentage of variation that each PC explains, you divide the PC eigenvalue by the sum over all the eigenvalues.

We will now quick and dirty plot the PCs using R.


Open R and paste the following code to plot your PCs

```
WD<-getwd()
setwd(WD)
library(calibrate)
## Define these
evec<- read.table ("plink.eigenvec")
eval<- read.table ("plink.eigenval")
namer <- "Merged_data"
nrpc<-10
## Script start
totalev <-sum(eval)
aa <- array(NA,dim=c(nrpc,1))
for (i in 1:nrpc) {
aa[i,1]<-format(round(((eval[i,1]/totalev)*100),3), nsmall = 3)}
pdf (file =paste(namer, "_PCA1.pdf", sep=""), width =10, height = 15, pointsize =12)
par(mfrow=c(3,2), oma=c(0,0,4,0))
plot (evec[,3], evec[,4], col = 0, pch = 0, xlab=paste("PC1: ", aa[1,1], "%", sep=""), ylab=paste("PC2: ", aa[2,1], "%", sep=""))
text(evec[,3], evec[,4], evec[,1], cex = 1, col = as.numeric(evec[,1]))
plot (evec[,5], evec[,6], col = 0, pch = 0, xlab=paste("PC3: ", aa[3,1], "%", sep=""), ylab=paste("PC4: ", aa[4,1], "%", sep=""))
text(evec[,5], evec[,6], evec[,1], cex = 1, col = as.numeric(evec[,1]))
plot (evec[,7], evec[,8], col = 0, pch = 0, xlab=paste("PC5: ", aa[5,1], "%", sep=""), ylab=paste("PC6: ", aa[6,1], "%", sep=""))
text(evec[,7], evec[,8], evec[,1], cex = 1, col = as.numeric(evec[,1]))
plot (evec[,9], evec[,10], col = 0, pch = 0, xlab=paste("PC7: ", aa[7,1], "%", sep=""), ylab=paste("PC8: ", aa[8,1], "%", sep=""))
text(evec[,9], evec[,10], evec[,1], cex = 1, col = as.numeric(evec[,1]))
plot (evec[,11], evec[,12], col = 0, pch = 0, xlab=paste("PC9: ", aa[9,1], "%", sep=""), ylab=paste("PC10: ", aa[10,1], "%", sep=""))
text(evec[,11], evec[,12], evec[,1], cex = 1, col = as.numeric(evec[,1]))
plot (evec[,11], evec[,12], col = 0, pch = 0, xlab = " ", ylab = " ", axes = FALSE)
title(paste(namer, "PC plot"), outer=TRUE, cex.main = 3) 
dev.off()
q()
N
```

See if you understand the code above. It basically plot PC1vsPC2 etc, and put labels on the plot.

Look at the output PDF. Does the results of your population PCA correspond to the population structure results you got from the ADMIXTURE plots? How many of the PCs do you think contain useful information. What part of the variation is represented by each of the PCs. Can you see the percentage variation that each PC explains?

You can also have a look at the PCA projection that I generated with one of my scripts. You will find it in the `DATA` folder. Dowload it and open it with a web browser.

You should now have enough infromation to answer the questions posed at the top of this documents. Remember to read the report instructions carefully!
Depending on how much time this took there might be time for you to go through Optional 2 below. 


=============================================================================


## Optional - MALDER
*Pleas read through the instructions of this section before running the commands, some of them you will want to change yourself first*

The analysis that we have done before are quite typical starting out analysis for population genetics. They are a way of getting an initial feel for the data and some initial hypothesis. ADMIXTURE and PCA are not formal tests for admixture, if we want to say with some confidence that a populaiton is admixed then we have to do a more formal test.
One such software is MALDER, which stands for Multiple ALDER. 
It uses multiple iterations of ALDER to estimates possible admixture event. This is based on decay of linkage disequilibrium.  


MALDER requires our data to be in the EIGENSTRAT format. We can convert our PLINK files to EIGENSTRAT using the `convertf` software from the software pack `Eigensoft`.

First we need a parameters file like so:

```
genotypename:  Merged_data.bed
snpname:  Merged_data.bim
indivname:  Merged_data.fam
outputformat: EIGENSTRAT
genotypeoutname: Merged_data.geno
snpoutname: Merged_data.snp
indivoutname: Merged_data.ind
```
Save it to `convertf_par_file.txt`.

To run convertf first load eigensoft:

```
module load eigensoft/7.2.1
```

then run it:

```
convertf -p convertf_par_file.txt
```

There is one aditional problem, the formats are not exactly the same so we will have to manipulate the `.ind` file a bit further. We need to replace the last column with the population name from the first column. We can do it in three step:

```
cut -f 1 -d ":" Merged_data.ind > pops
sed 's/Control//' Merged_data.ind > removed
paste pops removed > Merged_data.ind2
```
If you are sure that the new file is correct you can rename it to `Merged_data.ind` or just use the new name in the section below, your choice. 
It will take a while, so if you don't want to wait simply copy the output results from the `DATA/EIGENSOFT` directory to your working directory.


### Running MALDER
Malder requires a parameter file as well, it can be as simple as follows:

```
genotypename: /path/to/data.geno
snpname:      /path/to/data.snp
indivname:    /path/to/data.ind
admixpop:     testpopC
refpops:      refpopA;refpopB
```

Where `admixpop` is the population that you want to test and the `refpops`.
If you want to read more about Malder you can have a look at the [Manual](https://github.com/joepickrell/malder/tree/master/MALDER). 
So,if we want to test the `Bezan` and see if they are admixed with `GaAdangbe `, `Sotho` & `Zulu` (you always need at least 3 sources) then our parameters file would look as follows:

```
genotypename:	Merged_data.geno
snpname:	Merged_data.snp
indivname:	Merged_data.ind
admixpop:	Bezan
refpops:	GaAdangbe;Zulu;Sotho
checkmap: NO
binsize: 0.00005
```

We would then run it like so:

If you want to see the output while it is runing and save to a file:

```
 malder -p malder_par.txt | tee logfile
```

Or just save it to a file 

```
malder -p malder_par.txt > logfile
```

Your Output is then a table produced at the end of the logfile. (You can use `GG` to go to the bottom of a file and `gg` to go to the top).

Malder will always utput one more result than it can "Support", so if you get to RESULT\_3 then you should be looking at RESULT\_2.

Copy the table into spreadsheet program such as excel or libre office and sort on the amp0. The biggest value is the most likely prediction from MALDER. Note that it uses scientific notation so don't be fooled by the exponentials. The time is given in generations ago, multiply by 25 to give a rough estimate of when the admixture took place. 

Feel free to try different sources and targets to try and best answer the questions.



